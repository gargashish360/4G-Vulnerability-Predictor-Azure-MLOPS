"""
Script for deploying ONNX model to endpoint
"""
import logging
from logging.config import fileConfig
import os
import sys
from pathlib import Path
from azureml.core import Workspace
from azureml.core.model import Model
from azureml.core.model import InferenceConfig
from azureml.core.environment import Environment
from azureml.core.webservice import AciWebservice
from azureml.core.authentication import ServicePrincipalAuthentication
from azureml.core.conda_dependencies import CondaDependencies 


parent_dir = Path(os.path.realpath(__file__))
sys.path.append(str(parent_dir.parents[1]))
from config import config

parent_dir = Path(os.path.realpath(__file__))
fileConfig(str(parent_dir.parents[1]) + "/config/" + "logging_config.ini")
logger = logging.getLogger(__name__)


logger.info("Initializing service principal authentication")
svc_pr = ServicePrincipalAuthentication(
    tenant_id=config.AZURE_TENANT_ID,
    service_principal_id=config.AZURE_CLIENT_ID,
    service_principal_password=config.AZURE_CLIENT_SECRET,
)

logger.info("Creating workspace")
workspace = Workspace(
    subscription_id=config.SUBSCRIPTION_ID,
    resource_group=config.RESOURCE_GROUP,
    workspace_name=config.WORKSPACE,
    auth=svc_pr,
)

logger.info("Registering model")
model = Model.register(
    workspace=workspace,
    model_path=str(parent_dir.parents[1]) + "/best_model_artifacts/" + "best_model.onnx",
    model_name="4g_classification_best_model",
    tags={"onnx": "4g_best_model"},
    description="Best 4g classification model",
)

logger.info("Create Conda environment")
myenv = CondaDependencies.create(pip_packages=["numpy", "onnxruntime", "azureml-core", "azureml-defaults"])
with open(str(parent_dir.parent/"myenv.yml"),"w") as f:
    f.write(myenv.serialize_to_string())
myenv = Environment.from_conda_specification(name="myenv", file_path=str(parent_dir.parent/"myenv.yml"))

logger.info("Deploying inference endpoint")
inference_config = InferenceConfig(entry_script=str(parent_dir.parent / "score.py"), environment=myenv)
aciconfig = AciWebservice.deploy_configuration(
    cpu_cores=2,
    memory_gb=2,
    tags={"demo": "best_4g"},
    description="ONNX for best 4g classification model",
)
aci_service_name = "best-model-4g-clf"
print("Service", aci_service_name)
aci_service = Model.deploy(
    workspace, aci_service_name, [model], inference_config, aciconfig, overwrite=True
)
aci_service.wait_for_deployment(True)
print(aci_service.state)
print(aci_service.scoring_uri)
