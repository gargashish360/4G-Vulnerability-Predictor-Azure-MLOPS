import mlflow
from sklearn.model_selection import train_test_split
from azureml.core import Dataset, Datastore, Workspace
from azureml.core.run import Run
from azure.identity import DefaultAzureCredential
from azure.ai.ml import MLClient
from sklearn.model_selection import train_test_split
import os
from ray import air, tune
from ray.air.integrations.mlflow import MLflowLoggerCallback, setup_mlflow
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
import argparse

os.environ["AZURE_CLIENT_ID"] = "9220bb71-8bbd-4aa9-a07b-ff287ab39f35"  # service principal's app id
os.environ["AZURE_TENANT_ID"] = "608bf83f-6d9a-4888-ad38-d95f1528c410" # id of the principal's Azure Active Directory tenant
os.environ["AZURE_CLIENT_SECRET"] = "CZX8Q~lkcwdVpXYq9o2YTgLMSIb.eCcNm4Ds~dno" # one of the service principal's client secrets

def register_dataset(
    aml_workspace: Workspace,
    dataset_name: str,
    datastore_name: str,
    file_path: str
) -> Dataset:
    datastore = Datastore.get(aml_workspace, datastore_name)
    dataset = Dataset.Tabular.from_delimited_files(path=(datastore, file_path), separator=';')
    dataset = dataset.register(workspace=aml_workspace,
                               name=dataset_name,
                               create_new_version=True)

    return dataset

def train_function(config):
    if config["choice"] == "LogisticRegression":
        model = LogisticRegression(C=config["log_reg"]["C"])
    elif config["choice"] == "RandomForest":
         model = RandomForestClassifier(n_estimators=config["rand_forest_estimator"], max_depth=config["random_forest_depth"])
    else:
         raise ValueError("Invalid choice")
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    tune.report(accuracy=accuracy)

def tune_with_callback(mlflow_tracking_uri, finish_fast=False):
    tuner = tune.Tuner(
        train_function,
        tune_config=tune.TuneConfig(
            num_samples= 5
        ),
        run_config=air.RunConfig(
            name="mlflow",
            callbacks=[
                MLflowLoggerCallback(
                    tracking_uri=mlflow_tracking_uri,
                    experiment_name="4g_classification",
                    save_artifact=True,
                )
            ],
        ),
        param_space={
            "log_reg": {"C": tune.loguniform(0.01, 10)},   
            "rand_forest_estimator": tune.grid_search([100, 200]),
            "random_forest_depth": tune.grid_search([10, 20]),
            "choice": tune.grid_search(["LogisticRegression", "RandomForest"])
        },
    )
    results = tuner.fit()

if __name__ == '__main__':
    parser = argparse.ArgumentParser("train")
    parser.add_argument(
        "--data_file_path",
        type = str,
        help = ("data file path if specified else a new version of the dataset will be registered"),
        default = "ML-MATT-CompetitionQT2021_train.csv",
    )
    parser.add_argument(
        "--dataset_name",
        type=str,
        help = "Dataset name",
        default = "ML-MATT-CompetitionQT2021"
    )

    args = parser.parse_args()
    print("Argument [data_file_path]: %s" % args.data_file_path)
    print("Argument [dataset_name]: %s" % args.dataset_name)
    data_file_path = args.data_file_path
    dataset_name = args.dataset_name

    run = Run.get_context()
    # Get the dataset.
    if(dataset_name):
        if (data_file_path == 'none'):
            dataset = Dataset.get_by_name(run.experiment.workspace, dataset_name)
        else:
            dataset = register_dataset(run.experiment.workspace, dataset_name, "workspaceblobstore", data_file_path)
    else:
        e = ("No dataset provided")
        print(e)
        raise Exception(e)
    # Link dataset to the step run so it is trackable in the UI
    run.input_datasets['training_data'] = dataset
    subscription_id = "33579ab2-7df4-4870-ada1-4db803eff7ad"
    resource_group = "NM_Analytics"
    workspace = "nm_analytics_poc_ml"

    #Setting Default Credentials:
    credentials = DefaultAzureCredential()
    ml_client = MLClient(
        subscription_id=subscription_id,
        resource_group_name=resource_group,
        credential=credentials,
        )
    
    #Setting the workspace and mlflow tracking uri.
    ws = ml_client.workspaces.get(name=workspace)
    mlflow.set_tracking_uri(ws.mlflow_tracking_uri)

    # Data Preprocessing:
    dataset = dataset.to_pandas_dataframe()
    print("Dataframe_Shape", dataset.shape)
    dataset.drop_duplicates()
    dataset = dataset.drop(columns = ['Time', 'CellName'])
    y = dataset['Unusual']
    X = dataset.drop('Unusual', axis=1)
    X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=42)
    smoke_test = False
    mlflow_tracking_uri = ws.mlflow_tracking_uri
    #Generate Experiments
    tune_with_callback(mlflow_tracking_uri, finish_fast=smoke_test)